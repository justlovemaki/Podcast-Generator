#!/usr/bin/env python3
"""
OpenAI CLI - çº¯å‘½ä»¤è¡ŒOpenAIæ¥å£è°ƒç”¨å·¥å…·

æ”¯æŒä»¥ä¸‹åŠŸèƒ½ï¼š
- è‡ªå®šä¹‰APIå¯†é’¥ã€URLå’Œæ¨¡å‹åç§°
- äº¤äº’å¼èŠå¤©æ¨¡å¼
- å•æ¬¡æŸ¥è¯¢æ¨¡å¼
- æµå¼è¾“å‡º

ä½¿ç”¨æ–¹æ³•:

1. å®‰è£…ä¾èµ–:
   pip install openai

2. è®¾ç½®APIå¯†é’¥ (ä»¥ä¸‹ä»»æ„ä¸€ç§æ–¹å¼):
   - ç¯å¢ƒå˜é‡: export OPENAI_API_KEY="ä½ çš„APIå¯†é’¥"
   - å‘½ä»¤è¡Œå‚æ•°: python openai_cli.py --api-key "ä½ çš„APIå¯†é’¥"
   - é…ç½®æ–‡ä»¶ (config.json):
     {
       "api_key": "ä½ çš„APIå¯†é’¥",
       "base_url": "https://api.openai.com/v1",
       "model": "gpt-3.5-turbo",
       "temperature": 0.7,
       "top_p": 1.0
     }
     ç„¶åé€šè¿‡ --config config.json åŠ è½½

3. è¿è¡Œè„šæœ¬:

  - äº¤äº’å¼èŠå¤©æ¨¡å¼:
    python openai_cli.py [å¯é€‰å‚æ•°: --api-key VAL --base-url VAL --model VAL --temperature VAL --top-p VAL]
    åœ¨äº¤äº’æ¨¡å¼ä¸­ï¼Œè¾“å…¥ 'quit' æˆ– 'exit' é€€å‡ºï¼Œè¾“å…¥ 'clear' æ¸…ç©ºå¯¹è¯å†å²ã€‚

  - å•æ¬¡æŸ¥è¯¢æ¨¡å¼:
    python openai_cli.py --query "ä½ çš„é—®é¢˜" [å¯é€‰å‚æ•°: --api-key VAL --base-url VAL --model VAL --temperature VAL --top-p VAL --max-tokens VAL --system-message VAL]

  - ä½¿ç”¨é…ç½®æ–‡ä»¶:
    python openai_cli.py --config config.json --query "ä½ çš„é—®é¢˜"

ç¤ºä¾‹:
  python openai_cli.py
  python openai_cli.py -q "ä½ å¥½ï¼Œä¸–ç•Œ" -m gpt-4
  python openai_cli.py -q "ä½ å¥½ï¼Œä¸–ç•Œ" --temperature 0.8 --top-p 0.9
  python openai_cli.py --config my_config.json
"""

import argparse
import os
import sys
import json
from typing import Optional, Any, List, Union
import openai
from openai.types.chat import ChatCompletionMessageParam


class OpenAICli:
    def __init__(self, api_key: Optional[str] = None, base_url: Optional[str] = None, model: str = "gpt-3.5-turbo", system_message: Optional[str] = None):
        """åˆå§‹åŒ–CLIå®¢æˆ·ç«¯"""
        self.api_key = api_key or os.getenv("OPENAI_API_KEY")
        self.model = model or os.getenv("OPENAI_MODEL", "gpt-3.5-turbo")
        self.system_message = system_message
        
        if not self.api_key:
            raise ValueError("APIå¯†é’¥ä¸èƒ½ä¸ºç©ºï¼Œè¯·é€šè¿‡å‚æ•°æˆ–ç¯å¢ƒå˜é‡OPENAI_API_KEYè®¾ç½®")

        # openai.OpenAI å®¢æˆ·ç«¯ä¼šè‡ªåŠ¨å¤„ç† base_url çš„é»˜è®¤å€¼ï¼Œå¦‚æœä¼ å…¥ None
        # å¦‚æœ base_url ä¼ å…¥çš„æ˜¯ None æˆ–ç©ºå­—ç¬¦ä¸²ï¼Œåˆ™ä½¿ç”¨ OpenAI é»˜è®¤çš„ API base
        # å¦åˆ™ï¼Œä½¿ç”¨ä¼ å…¥çš„ base_url
        effective_base_url = None
        if base_url:
            effective_base_url = base_url
        elif os.getenv("OPENAI_BASE_URL"):
            effective_base_url = os.getenv("OPENAI_BASE_URL")
        
        self.client = openai.OpenAI(api_key=self.api_key, base_url=effective_base_url)
    
    def chat_completion(self, messages: List[ChatCompletionMessageParam], temperature: float = 0.7, top_p: float = 1.0, max_tokens: Optional[int] = None) -> Any:
        """å‘é€èŠå¤©å®Œæˆè¯·æ±‚"""
        # å¤„ç†ç³»ç»Ÿæç¤ºè¯
        messages_to_send = list(messages)  # åˆ›å»ºä¸€ä¸ªå‰¯æœ¬ä»¥é¿å…ä¿®æ”¹åŸå§‹åˆ—è¡¨
        
        system_message_present = False
        if messages_to_send and messages_to_send[0].get("role") == "system":
            system_message_present = True

        if self.system_message:
            if system_message_present:
                # æ›´æ–°ç°æœ‰çš„ç³»ç»Ÿæç¤ºè¯
                messages_to_send[0]["content"] = self.system_message
            else:
                # æ’å…¥æ–°çš„ç³»ç»Ÿæç¤ºè¯
                messages_to_send.insert(0, {"role": "system", "content": self.system_message})

        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages_to_send,  # ä½¿ç”¨åŒ…å«ç³»ç»Ÿæç¤ºè¯çš„åˆ—è¡¨
                temperature=temperature,
                top_p=top_p,
                max_tokens=max_tokens,
                stream=True
            )
            return response
        except Exception as e:
            raise Exception(f"APIè°ƒç”¨å¤±è´¥: {str(e)}")
    
    def interactive_chat(self):
        """å¯åŠ¨äº¤äº’å¼èŠå¤©æ¨¡å¼"""
        print(f"ğŸ¤– OpenAI CLI å·²å¯åŠ¨ (æ¨¡å‹: {self.model})")
        print("è¾“å…¥ 'quit' æˆ– 'exit' é€€å‡ºï¼Œè¾“å…¥ 'clear' æ¸…ç©ºå¯¹è¯å†å²")
        print("-" * 50)
        
        messages: List[ChatCompletionMessageParam] = []
        # ç§»é™¤æ­¤å¤„æ·»åŠ system_messageçš„é€»è¾‘ï¼Œå› ä¸ºå®ƒå·²åœ¨chat_completionä¸­å¤„ç†
        
        while True:
            try:
                user_input = input("\nä½ : ").strip()
                
                if user_input.lower() in ['quit', 'exit', 'q']:
                    print("ğŸ‘‹ å†è§ï¼")
                    break
                
                if user_input.lower() == 'clear':
                    messages = []
                    print("ğŸ—‘ï¸ å¯¹è¯å†å²å·²æ¸…ç©º")
                    continue
                
                if not user_input:
                    continue
                
                messages.append({"role": "user", "content": user_input})
                
                print("AI: ", end="", flush=True)
                
                response_generator = self.chat_completion(messages)
                ai_message_full = ""
                for chunk in response_generator:
                    if chunk.choices and chunk.choices[0].delta.content:
                        content = chunk.choices[0].delta.content
                        print(content, end="", flush=True)
                        ai_message_full += content
                print() # Print a newline at the end of the AI's response
                messages.append({"role": "assistant", "content": ai_message_full})
                
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ å†è§ï¼")
                break
            except Exception as e:
                print(f"\nâŒ é”™è¯¯: {str(e)}")
    
    def single_query(self, query: str, temperature: float = 0.7, top_p: float = 1.0, max_tokens: Optional[int] = None):
        """å•æ¬¡æŸ¥è¯¢æ¨¡å¼"""
        messages: List[ChatCompletionMessageParam] = []
        # ç§»é™¤æ­¤å¤„æ·»åŠ system_messageçš„é€»è¾‘ï¼Œå› ä¸ºå®ƒå·²åœ¨chat_completionä¸­å¤„ç†
        messages.append({"role": "user", "content": query})
        
        try:
            response_generator = self.chat_completion(messages, temperature, top_p, max_tokens)
            for chunk in response_generator:
                if chunk.choices and chunk.choices[0].delta.content:
                    print(chunk.choices[0].delta.content, end="", flush=True)
            print() # Ensure a newline at the end
        except Exception as e:
            print(f"é”™è¯¯: {str(e)}", file=sys.stderr)
            sys.exit(1)


def main():
    parser = argparse.ArgumentParser(description="OpenAI CLI - ä½¿ç”¨litellmçš„çº¯å‘½ä»¤è¡Œå·¥å…·")
    
    # åŸºæœ¬å‚æ•°
    parser.add_argument("--api-key", "-k", help="OpenAI APIå¯†é’¥")
    parser.add_argument("--base-url", "-u", help="APIåŸºç¡€URL")
    parser.add_argument("--model", "-m", default="gpt-3.5-turbo", help="æ¨¡å‹åç§°")
    
    # æŸ¥è¯¢å‚æ•°
    parser.add_argument("--query", "-q", help="å•æ¬¡æŸ¥è¯¢çš„é—®é¢˜")
    parser.add_argument("--temperature", "-t", type=float, default=1, help="æ¸©åº¦å‚æ•° (0.0-2.0)")
    parser.add_argument("--top-p", type=float, default=0.95, help="Top-pé‡‡æ ·å‚æ•° (0.0-1.0)")
    parser.add_argument("--max-tokens", type=int, help="æœ€å¤§tokenæ•°")
    parser.add_argument("--system-message", "-s", help="ç³»ç»Ÿæç¤ºè¯")
    
    # é…ç½®æ–‡ä»¶
    parser.add_argument("--config", "-c", help="é…ç½®æ–‡ä»¶è·¯å¾„ (JSONæ ¼å¼)")
    
    args = parser.parse_args()
    
    # åŠ è½½é…ç½®æ–‡ä»¶
    config = {}
    if args.config and os.path.exists(args.config):
        try:
            with open(args.config, 'r', encoding='utf-8') as f:
                config = json.load(f)
        except Exception as e:
            print(f"é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥: {str(e)}", file=sys.stderr)
            sys.exit(1)
    
    # åˆå¹¶é…ç½®ä¼˜å…ˆçº§: å‘½ä»¤è¡Œå‚æ•° > é…ç½®æ–‡ä»¶ > ç¯å¢ƒå˜é‡
    api_key = args.api_key or config.get("api_key")
    base_url = args.base_url or config.get("base_url")
    model = args.model or config.get("model", "gpt-3.5-turbo")
    system_message = args.system_message or config.get("system_message")
    temperature = args.temperature or config.get("temperature", 1)
    top_p = args.top_p or config.get("top_p", 0.95)
    
    try:
        cli = OpenAICli(api_key=api_key, base_url=base_url, model=model, system_message=system_message)
        
        if args.query:
            # å•æ¬¡æŸ¥è¯¢æ¨¡å¼
            cli.single_query(args.query, temperature, top_p, args.max_tokens)
        else:
            # äº¤äº’å¼æ¨¡å¼
            cli.interactive_chat()
            
    except ValueError as e:
        print(f"é…ç½®é”™è¯¯: {str(e)}", file=sys.stderr)
        sys.exit(1)
    except Exception as e:
        print(f"è¿è¡Œæ—¶é”™è¯¯: {str(e)}", file=sys.stderr)
        sys.exit(1)


if __name__ == "__main__":
    main()